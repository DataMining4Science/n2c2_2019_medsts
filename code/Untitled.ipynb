{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "medsts_path = '/home/dc925/project/data/seq_pair/MEDSTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'[\\d]*', '', sent)\n",
    "    sent = re.sub(r'[^\\w\\s]', ' ', sent)\n",
    "\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = os.path.join(medsts_path, 'data.jsonl')\n",
    "with open(original, 'r') as f:\n",
    "    lines = []\n",
    "    for line in f:\n",
    "        example = json.loads(line)\n",
    "        example['sentence1'] = preprocess_text(example['sentence1'])\n",
    "        example['sentence2'] = preprocess_text(example['sentence2'])\n",
    "        lines.append(example)\n",
    "    size = len(lines)\n",
    "    \n",
    "    \n",
    "final_fold_path = os.path.join(medsts_path, 'k_fold_{}'.format(k))\n",
    "os.makedirs(final_fold_path, exist_ok=True)\n",
    "train_out = os.path.join(final_fold_path, 'train.jsonl')\n",
    "dev_out = os.path.join(final_fold_path, 'dev.jsonl')\n",
    "random.shuffle(lines)\n",
    "train = lines[:1496]\n",
    "dev = lines[1496:]\n",
    "\n",
    "\n",
    "with open(train_out, 'w') as f:\n",
    "    for line in train:\n",
    "        json.dump(line, fp=f)\n",
    "        f.write('\\n')\n",
    "with open(dev_out, 'w') as f:\n",
    "    for line in dev:\n",
    "        json.dump(line, fp=f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that's k_fold_5, finished running data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_dir = '/home/dc925/project/medsts/logits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = [pd.read_csv(os.path.join(logits_dir, 'fold_{}_logits.csv'.format(k)), index_col=0) for k in folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t 0.9723686026516355\n",
      "5 \t 0.9733891813705723\n",
      "7 \t 0.974915495046161\n",
      "9 \t 0.9752763831899556\n",
      "11 \t 0.9765627270055668\n",
      "13 \t 0.9766621111788025\n",
      "15 \t 0.977025612242817\n",
      "17 \t 0.9770821602887577\n",
      "19 \t 0.9772765435990991\n",
      "21 \t 0.9773606067189637\n",
      "0.9773606067189637\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "best_val = 0\n",
    "best_n = 0\n",
    "for n in range(3, 288 * 3 // 5, 2):\n",
    "    ensemble_table = logits[k]\n",
    "    top_cols = ensemble_table.corr().sort_values(by='label', axis=1, ascending=False).columns[1:n+1]\n",
    "    ensemble_table['ensemble'] = ensemble_table[top_cols].mean(axis=1)\n",
    "    val = ensemble_table.corr().iloc[0,-1:].item()\n",
    "    if val > best_val:\n",
    "        best_val = val\n",
    "        best_n = n\n",
    "        print('{} \\t {}'.format(best_n, best_val))\n",
    "print(best_val)\n",
    "print(best_n)\n",
    "top_cols = ensemble_table.corr().sort_values(by='label', axis=1, ascending=False).columns[1:best_n+1]\n",
    "ensemble_table['ensemble'] = ensemble_table[top_cols].mean(axis=1)\n",
    "tables.append(ensemble_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, we want to extract pid:ensemble prediction for each fold and aggregate them across folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in folds:\n",
    "    for pid, pred in tables[k]['ensemble'].items():\n",
    "        pred = round(pred, 4)\n",
    "        if pid in soft_labels:\n",
    "            soft_labels[pid].append(pred)\n",
    "        else:\n",
    "            soft_labels[pid] = [pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_labels_ave = {k:round(np.mean(v), 4) for k, v in soft_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in train.jsonl from k_fold_5 and write in averaged soft label for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1641"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_labels_ave.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(medsts_path, 'k_fold_9/train.jsonl')\n",
    "with open(train_path, 'r') as f:\n",
    "    train = []\n",
    "    for line in f:\n",
    "        example = json.loads(line)\n",
    "        train.append(example)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_labels_ave[1275] = 3.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soft_labels_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "for example in train:\n",
    "    for pid, soft_label in soft_labels_ave.items():\n",
    "        if example['pid'] == pid:\n",
    "            t +=1\n",
    "            example['label_soft'] = soft_label\n",
    "    if 'label_soft' not in example:\n",
    "        example['label_soft'] = example['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ex in train:\n",
    "#     print('{} \\t {} \\t {}'.format(ex['pid'], ex['label'], ex['label_soft']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soft_labels_ave' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-53006a70f739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoft_labels_ave\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m871\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'soft_labels_ave' is not defined"
     ]
    }
   ],
   "source": [
    "soft_labels_ave[871]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, 'w') as f:\n",
    "    for line in train:\n",
    "        json.dump(line, fp=f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_strings(mappings, sentence):\n",
    "    strings = []\n",
    "    for phrase in mappings:\n",
    "        if phrase['mapping']:\n",
    "            for m in phrase['mapping']:\n",
    "                text = m['preferred'].lower().split()\n",
    "                strings += text\n",
    "                \n",
    "                if 'Clinical Drug' in m['semtypes']:\n",
    "                    strings += ['clinical drug']\n",
    "                if 'Pharmacologic Substance' in m['semtypes']:\n",
    "                    strings += ['pharmacologic substance']\n",
    "    out = \" \".join(strings)\n",
    "    out = re.sub(r'[^\\w\\s]', ' ', out)\n",
    "    out = out.split()\n",
    "    out = [t for t in out if t not in banned_words and t not in sentence]\n",
    "    out = list(set(out))\n",
    "    out = \" \".join(out)\n",
    "    return out\n",
    "\n",
    "def augment_sentences(mm_output, data):\n",
    "\n",
    "    assert len(mm_output) == len(data)*2\n",
    "    i = 0\n",
    "    j = 0\n",
    "    augment_strings = []\n",
    "    while i < len(mm_output)-1:\n",
    "        aug = extract_strings(mm_output[i], data[j]['sentence1'])\n",
    "        data[j]['augment1'] = aug\n",
    "        i += 1\n",
    "        aug = extract_strings(mm_output[i], data[j]['sentence2'])\n",
    "        data[j]['augment2'] = aug\n",
    "        i += 1\n",
    "        j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/dc925/project/data/seq_pair/MEDSTS/k_fold_9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mapping_path = 'filtered_test.p'\n",
    "train_mapping_path = 'filtered_train.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, test_mapping_path), 'rb') as f:\n",
    "    test_mapping = pickle.load(f)\n",
    "with open(os.path.join(data_dir, train_mapping_path), 'rb') as f:\n",
    "    train_mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(data_dir, 'test.jsonl')\n",
    "with open(test_path, 'r') as f:\n",
    "    test = []\n",
    "    for line in f:\n",
    "        example = json.loads(line)\n",
    "        test.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "banned_words = ['contextual', 'qualifier', 'value', 'action', '-', 'patients', 'of', 'person', 'feels', 'time', 'to', \\\n",
    "               'contents', 'escalation', 'cavity', 'region', 'medical', 'discussion', 'procedure', 'unit', 'dose', 'appearance', \\\n",
    "               'feelings', 'has', 'does', 'finding', 'function', 'in', 'qualitative', 'changing', 'publication', 'educational', \\\n",
    "                'by', 'for', 'with', 'from', 'continuous', 'transducers', 'process', 'needs', 'individual', 'reporting', 'chief', \\\n",
    "               'relationships', '6', '10', 'syncytial', 'human', 'masks', 'muscle', 'training', 'virus',]\n",
    "\n",
    "augment_sentences(test_mapping, test)\n",
    "augment_sentences(train_mapping, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3284"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, 'w') as f:\n",
    "    for line in test:\n",
    "        json.dump(line, fp=f)\n",
    "        f.write('\\n')\n",
    "with open(train_path, 'w') as f:\n",
    "    for line in train:\n",
    "        json.dump(line, fp=f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
